
@article{inta_chimera:_2012,
	title = {The {“Chimera”:} An Off-The-Shelf {CPU/GPGPU/FPGA} Hybrid Computing Platform},
	volume = {2012},
	issn = {1687-7195, 1687-7209},
	shorttitle = {The {“Chimera”}},
	url = {http://www.hindawi.com/journals/ijrc/2012/241439/},
	doi = {10.1155/2012/241439},
	urldate = {2012-12-04},
	journal = {International Journal of Reconfigurable Computing},
	author = {Inta, Ra and Bowman, David J. and Scott, Susan M.},
	year = {2012},
	pages = {1--10},
	file = {The “Chimera”: An Off-The-Shelf CPU/GPGPU/FPGA Hybrid Computing Platform:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/HWW4QGZ9/241439.html:application/xhtml+xml;The “Chimera” An Off-The-Shelf CPU-GPGPU-FPGA Hybrid Computing Platform .pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/MSD5ZFAB/The “Chimera” An Off-The-Shelf CPU-GPGPU-FPGA Hybrid Computing Platform .pdf:application/pdf}
},

@misc{anon._dwarf_????,
	title = {Dwarf Mine - View},
	url = {http://view.eecs.berkeley.edu/wiki/Dwarfs},
	urldate = {2013-02-12},
	author = {{Anon.}},
	file = {Dwarf Mine - View:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/V7X63W5F/Dwarfs.html:text/html}
},

@incollection{dalal_human_2006,
	series = {Lecture Notes in Computer Science},
	title = {Human Detection Using Oriented Histograms of Flow and Appearance},
	copyright = {©2006 Springer Berlin Heidelberg},
	isbn = {978-3-540-33834-5, 978-3-540-33835-2},
	url = {http://link.springer.com/chapter/10.1007/11744047_33},
	abstract = {Detecting humans in films and videos is a challenging problem owing to the motion of the subjects, the camera and the background and to variations in pose, appearance, clothing, illumination and background clutter. We develop a detector for standing and moving people in videos with possibly moving cameras and backgrounds, testing several different motion coding schemes and showing empirically that orientated histograms of differential optical flow give the best overall performance. These motion-based descriptors are combined with our Histogram of Oriented Gradient appearance descriptors. The resulting detector is tested on several databases including a challenging test set taken from feature films and containing wide ranges of pose, motion and background variations, including moving cameras and backgrounds. We validate our results on two challenging test sets containing more than 4400 human examples. The combined detector reduces the false alarm rate by a factor of 10 relative to the best appearance-based detector, for example giving false alarm rates of 1 per 20,000 windows tested at 8\% miss rate on our Test Set 1.},
	number = {3952},
	urldate = {2013-02-12},
	booktitle = {Computer Vision – {ECCV} 2006},
	publisher = {Springer Berlin Heidelberg},
	author = {Dalal, Navneet and Triggs, Bill and Schmid, Cordelia},
	editor = {Leonardis, Aleš and Bischof, Horst and Pinz, Axel},
	month = jan,
	year = {2006},
	keywords = {Artificial Intelligence (incl. Robotics), computer graphics, Image Processing and Computer Vision, Pattern Recognition},
	pages = {428--441},
	file = {Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/NGMM7QJT/10.html:text/html}
},

@article{herbordt_achieving_2007,
	title = {Achieving High Performance with {FPGA-Based} Computing},
	volume = {40},
	issn = {0018-9162},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3098506/},
	doi = {10.1109/MC.2007.79},
	abstract = {Numerous application areas, including bioinformatics and computational biology, demand increasing amounts of processing capability. In many cases, the computation cores and data types are suited to field-programmable gate arrays. The challenge is identifying the design techniques that can extract high performance potential from the {FPGA} fabric.},
	number = {3},
	urldate = {2013-01-26},
	journal = {Computer},
	author = {Herbordt, Martin C. and {VanCourt}, Tom and Gu, Yongfeng and Sukhwani, Bharat and Conti, Al and Model, Josh and {DiSabello}, Doug},
	month = mar,
	year = {2007},
	note = {{PMID:} 21603088
{PMCID:} {PMC3098506}},
	pages = {50--57},
	file = {PubMed Central Full Text PDF:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/6S35ZS8M/Herbordt et al. - 2007 - Achieving High Performance with FPGA-Based Computi.pdf:application/pdf}
},

@inproceedings{dalal_histograms_2005,
	title = {Histograms of oriented gradients for human detection},
	volume = {1},
	doi = {10.1109/CVPR.2005.177},
	abstract = {We study the question of feature sets for robust visual object recognition; adopting linear {SVM} based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient ({HOG)} descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original {MIT} pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	booktitle = {{IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2005. {CVPR} 2005},
	author = {Dalal, N. and Triggs, B.},
	month = jun,
	year = {2005},
	keywords = {coarse spatial binning, contrast normalization, edge based descriptors, feature extraction, fine orientation binning, fine-scale gradients, gradient based descriptors, gradient methods, high performance computing, Histograms, histograms of oriented gradients, human detection, Humans, Image databases, Image edge detection, linear {SVM}, Object detection, Object recognition, overlapping descriptor, pedestrian database, Robustness, robust visual object recognition, Support vector machines, Testing},
	pages = {886 --893 vol. 1},
	file = {HOG_original.pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/2MD6RUIT/HOG_original.pdf:application/pdf;IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/VA3VVSJC/login.html:text/html}
},

@inproceedings{che_accelerating_2008,
	title = {Accelerating Compute-Intensive Applications with {GPUs} and {FPGAs}},
	doi = {10.1109/SASP.2008.4570793},
	abstract = {Accelerators are special purpose processors designed to speed up compute-intensive sections of applications. Two extreme endpoints in the spectrum of possible accelerators are {FPGAs} and {GPUs}, which can often achieve better performance than {CPUs} on certain workloads. {FPGAs} are highly customizable, while {GPUs} provide massive parallel execution resources and high memory bandwidth. Applications typically exhibit vastly different performance characteristics depending on the accelerator. This is an inherent problem attributable to architectural design, middleware support and programming style of the target platform. For the best application-to-accelerator mapping, factors such as programmability, performance, programming cost and sources of overhead in the design flows must be all taken into consideration. In general, {FPGAs} provide the best expectation of performance, flexibility and low overhead, while {GPUs} tend to be easier to program and require less hardware resources. We present a performance study of three diverse applications - Gaussian elimination, data encryption standard ({DES)}, and Needleman-Wunsch - on an {FPGA}, a {GPU} and a multicore {CPU} system. We perform a comparative study of application behavior on accelerators considering performance and code complexity. Based on our results, we present an application characteristic to accelerator platform mapping, which can aid developers in selecting an appropriate target architecture for their chosen application.},
	author = {Che, Shuai and Li, Jie and Sheaffer, {J.W.} and Skadron, K. and Lach, J.},
	month = jun,
	year = {2008},
	keywords = {accelerator platform mapping, application-to-accelerator mapping, architectural design, code complexity, compute-intensive applications, coprocessors, cryptography, data encryption standard, field programmable gate arrays, {FPGA}, Gaussian elimination, Gaussian processes, {GPU}, massive parallel execution resources, middleware, middleware support, multicore {CPU} system, multiprocessing systems, Needleman-Wunsch, programming style},
	pages = {101 --107},
	file = {Accelerating Compute-Intensive Applications with GPUs and FPGAs.pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/5ZFCHNSN/Accelerating Compute-Intensive Applications with GPUs and FPGAs.pdf:application/pdf;IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/2TCEPSHR/login.html:text/html}
},

@article{kloosterman_zittenblijven_2009,
	title = {Zittenblijven of afstromen? De relatie tussen sociaal milieu en keuzes in het voortgezet onderwijs voor drie cohorten leerlingen},
	volume = {84},
	issn = {00259454},
	shorttitle = {Zittenblijven of afstromen?},
	url = {http://www.narcis.nl/publication/RecordID/oai:wo.uvt.nl:3749437},
	number = {1},
	urldate = {2013-03-23},
	journal = {Mens en Maatschappij},
	author = {Kloosterman, R. and Graaf, P. M. de},
	year = {2009},
	pages = {6--28},
	file = {Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/ZT3E8BCN/oaiwo.uvt.html:text/html}
},

@article{prisacariu_fasthog-real-time_2009,
	title = {{fastHOG-a} real-time {GPU} implementation of {HOG}},
	author = {Prisacariu, Victor Adrian and Reid, Ian},
	year = {2009}
},

@inproceedings{kalarot_comparison_2010,
	title = {Comparison of {FPGA} and {GPU} implementations of real-time stereo vision},
	doi = {10.1109/CVPRW.2010.5543743},
	abstract = {Real-time stereo vision systems have many applications - from autonomous navigation for vehicles through surveillance to materials handling. Accurate scene interpretation depends on an ability to process high resolution images in real-time, but, although the calculations for stereo matching are basically simple, a practical system needs to evaluate at least 109 disparities every second - beyond the capability of a single processor. Stereo correspondence algorithms have high degrees of inherent parallelism and are thus good candidates for parallel implementations. In this paper, we compare the performance obtainable with an {FPGA} and a {GPU} to understand the trade-off between the flexibility but relatively low speed of an {FPGA} and the high speed and fixed architecture of the {GPU.} Our comparison highlights the relative strengths and limitations of the two systems. Our experiments show that, for a range of image sizes, the {GPU} manages 2 {\#x00D7;} 109 disparities per second, compared with 2.6 {\#x00D7;} 109 disparities per second for an {FPGA.}},
	author = {Kalarot, R. and Morris, J.},
	month = jun,
	year = {2010},
	keywords = {autonomous navigation, computer graphic equipment, coprocessors, field programmable gate arrays, {FPGA} comparison, {GPU} implementations, image matching, materials handling, real-time stereo vision, real-time systems, scene interpretation, stereo image processing, stereo matching},
	pages = {9 --15},
	file = {Comparison of FPGA and GPU implementations of Real-time Stereo Vision .pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/UDAR5QV4/Comparison of FPGA and GPU implementations of Real-time Stereo Vision .pdf:application/pdf;IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/IZNCVJK4/login.html:text/html}
},

@article{martin_high-level_2009,
	title = {High-Level Synthesis: Past, Present, and Future},
	volume = {26},
	issn = {0740-7475},
	shorttitle = {High-Level Synthesis},
	doi = {10.1109/MDT.2009.83},
	abstract = {This article presents the history and evolution of {HLS} from research to industry adoption. The authors offer insights on why earlier attempts to gain industry adoption were not successful, why current {HLS} tools are finally seeing adoption, and what to expect as {HLS} evolves toward system-level design.},
	number = {4},
	journal = {{IEEE} Design Test of Computers},
	author = {Martin, G. and Smith, G.},
	month = aug,
	year = {2009},
	keywords = {Algorithm design and analysis, behavioral synthesis, Commercialization, commercial use, Computer industry, design and test, Electronic design automation and methodology, Electronics industry, {ESL} synthesis, Hardware, High level synthesis, high-level synthesis, History, {HLS} tools, industry adoption, Machinery production industries, Physics computing, system-level design},
	pages = {18 --25},
	file = {IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/JKJGTIBI/login.html:text/html}
},

@misc{anon._zynq-7000_2012,
	title = {Zynq-7000 All Programmable  {SoC:} Concepts, Tools, and  Techniques ({CTT)}},
	url = {http://www.xilinx.com/support/documentation/sw_manuals/xilinx14_2/ug873-zynq-ctt.pdf},
	urldate = {2013-02-13},
	publisher = {Xilinx},
	author = {{Anon.}},
	month = jul,
	year = {2012}
},

@incollection{buyukkurt_impact_2006,
	series = {Lecture Notes in Computer Science},
	title = {Impact of Loop Unrolling on Area, Throughput and Clock Frequency in {ROCCC:} C to {VHDL} Compiler for {FPGAs}},
	copyright = {©2006 Springer Berlin Heidelberg},
	isbn = {978-3-540-36708-6, 978-3-540-36863-2},
	shorttitle = {Impact of Loop Unrolling on Area, Throughput and Clock Frequency in {ROCCC}},
	url = {http://link.springer.com/chapter/10.1007/11802839_48},
	abstract = {Loop unrolling is the main compiler technique that allows reconfigurable architectures achieve large degrees of parallelism. However, loop unrolling increases the area and can potentially have a negative impact on clock cycle time. In most embedded applications, the critical parameter is the throughput. Loop unrolling can therefore have contradictory effects on the throughput. As a consequence there exists, in general, a degree of unrolling that maximizes the throughput per unit area. This paper studies the effect of loop unrolling on the area, clock speed and throughput within the {ROCCC}, C to {VHDL} compilation framework. Our results indicate that due to the unique design of the {ROCCC} compilation framework, {FPGA} area either shrinks or increases at a very low rate for the first few times the loops are unrolled. This reduced area causes the clock cycle time to decrease and thus a great gain in throughput. Our results also show that there are different optimal unrolling factors for different programs.},
	number = {3985},
	urldate = {2013-02-10},
	booktitle = {Reconfigurable Computing: Architectures and Applications},
	publisher = {Springer Berlin Heidelberg},
	author = {Buyukkurt, Betul and Guo, Zhi and Najjar, Walid A.},
	editor = {Bertels, Koen and Cardoso, João M. P. and Vassiliadis, Stamatis},
	month = jan,
	year = {2006},
	keywords = {Computer Communication Networks, Computer Hardware, Computer System Implementation, Processor Architectures, System Performance and Evaluation},
	pages = {401--412},
	file = {Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/C5CMWARI/10.html:text/html}
},

@inproceedings{kestur_blas_2010,
	title = {{BLAS} Comparison on {FPGA}, {CPU} and {GPU}},
	doi = {10.1109/ISVLSI.2010.84},
	abstract = {High Performance Computing ({HPC)} or scientific codes are being executed across a wide variety of computing platforms from embedded processors to massively parallel {GPUs.} We present a comparison of the Basic Linear Algebra Subroutines ({BLAS)} using double-precision floating point on an {FPGA}, {CPU} and {GPU.} On the {CPU} and {GPU}, we utilize standard libraries on state-of-the-art devices. On the {FPGA}, we have developed parameterized modular implementations for the dot-product and Gaxpy or matrix-vector multiplication. In order to obtain optimal performance for any aspect ratio of the matrices, we have designed a high-throughput accumulator to perform an efficient reduction of floating point values. To support scalability to large data-sets, we target the {BEE3} {FPGA} platform. We use performance and energy efficiency as metrics to compare the different platforms. Results show that {FPGAs} offer comparable performance as well as 2.7 to 293 times better energy efficiency for the test cases that we implemented on all three platforms.},
	author = {Kestur, S. and Davis, {J.D.} and Williams, O.},
	month = jul,
	year = {2010},
	keywords = {basic linear algebra subroutines, {CPU}, dot-product multiplication, double-precision floating point, embedded processors, energy efficiency, field programmable gate arrays, floating point values, {FPGA} optimizations, high performance computing, massively parallel {GPU}, matrix multiplication, matrix-vector multiplication, parameterized modular implementations, scientific codes},
	pages = {288 --293},
	file = {BLAS Comparison on FPGA, CPU and GPU .pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/TBCA72CW/BLAS Comparison on FPGA, CPU and GPU .pdf:application/pdf;IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/9BNICVP2/login.html:text/html}
},

@misc{_moores_????,
	title = {Moore’s Law Inspires Intel Innovation},
	url = {http://www.intel.com/content/www/us/en/silicon-innovations/moores-law-technology.html},
	abstract = {Bold forecast inspires the creation of groundbreaking new technologies and more power-efficient processors. (For embedded developers.)},
	urldate = {2013-01-26},
	journal = {Intel},
	keywords = {22nm, 32nm, 3-D Tri-Gate transistor, energy efficiency, fab network, Gordon Moore, Moore's Law, power-efficient {processors,Moore's} Law Inspires Intel Innovation, silicon, size, strength, transistor},
	file = {Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/HSFRAEPE/moores-law-technology.html:text/html}
},

@inproceedings{mcbader_fpga_2003,
	title = {An {FPGA} implementation of a flexible, parallel image processing architecture suitable for embedded vision systems},
	doi = {10.1109/IPDPS.2003.1213415},
	abstract = {This paper describes the design of a programmable parallel architecture that is to be used for signal pre-processing in intelligent embedded vision systems. The architecture has been implemented and tested using a Celoxica {RC1000} prototyping platform with a Xilinx {XCY2000E} {FPGA.} The system operates at a clock rate of 50 {MHz} and can perform pre-processing functions such as filtering, correlation and transformation on an image of 256x256 pixels at up to 667 frames/s.},
	booktitle = {Parallel and Distributed Processing Symposium, 2003. Proceedings. International},
	author = {{McBader}, S. and Lee, P.},
	month = apr,
	year = {2003},
	keywords = {Celoxica {RC1000} prototyping platform, Clocks, computer vision, embedded systems, embedded vision systems, field programmable gate arrays, Filtering, {FPGA} implementation, image processing, Intelligent systems, Machine vision, parallel architectures, parallel image processing architecture, programmable parallel architecture, Prototypes, Signal design, Testing, Xilinx {XCY2000E} {FPGA}},
	pages = {5 pp.},
	file = {IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/PFNXZBMC/login.html:text/html}
},

@misc{center_for_history_and_new_media_zotero_????,
	title = {Zotero Quick Start Guide},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}},
	annote = {Welcome to {Zotero!View} the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research {sources.Thanks} for installing Zotero.}
},

@article{cong_high-level_2011,
	title = {High-Level Synthesis for {FPGAs:} From Prototyping to Deployment},
	volume = {30},
	issn = {0278-0070},
	shorttitle = {High-Level Synthesis for {FPGAs}},
	doi = {10.1109/TCAD.2011.2110592},
	abstract = {Escalating system-on-chip design complexity is pushing the design community to raise the level of abstraction beyond register transfer level. Despite the unsuccessful adoptions of early generations of commercial high-level synthesis ({HLS)} systems, we believe that the tipping point for transitioning to {HLS} msystem-on-chip design complexityethodology is happening now, especially for field-programmable gate array ({FPGA)} designs. The latest generation of {HLS} tools has made significant progress in providing wide language coverage and robust compilation technology, platform-based modeling, advancement in core {HLS} algorithms, and a domain-specific approach. In this paper, we use {AutoESL's} {AutoPilot} {HLS} tool coupled with domain-specific system-level implementation platforms developed by Xilinx as an example to demonstrate the effectiveness of state-of-art C-to-{FPGA} synthesis solutions targeting multiple application domains. Complex industrial designs targeting Xilinx {FPGAs} are also presented as case studies, including comparison of {HLS} solutions versus optimized manual designs. In particular, the experiment on a sphere decoder shows that the {HLS} solution can achieve an 11-31\% reduction in {FPGA} resource usage with improved design productivity compared to hand-coded design.},
	number = {4},
	journal = {{IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Cong, J. and Liu, Bin and Neuendorffer, S. and Noguera, J. and Vissers, K. and Zhang, Zhiru},
	month = apr,
	year = {2011},
	keywords = {Algorithm design and analysis, {AutoESL} {AutoPilot} {HLS} tool, commercial high-level synthesis systems, C-to-{FPGA} synthesis solutions, Domain-specific design, domain-specific system-level implementation platforms, field-programmable gate array designs, field-programmable gate array ({FPGA)}, field programmable gate arrays, hand-coded design, Hardware, high-level synthesis ({HLS)}, improved design productivity, network synthesis, Optimization, platform-based modeling, Program processors, quality of results ({QoR)}, register transfer level, robust compilation technology, {SoC}, sphere decoder, System-on-a-chip, system-on-chip, system-on-chip design complexity, wide language coverage, Xilinx {FPGA}},
	pages = {473 --491},
	file = {IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/SSQ4CW3C/login.html:text/html}
},

@article{asanovic_landscape_????,
	title = {The landscape of parallel computing research: A view from Berkeley (2006)},
	shorttitle = {The landscape of parallel computing research},
	journal = {Electrical Engineering and Computer Sciences University of California at Berkeley. http://www. eecs. berkeley. {edu/Pubs/TechRpts/2006/EECS-2006-183.} pdf},
	author = {Asanovic, K. and Bodik, R. and Catanzaro, B. C. and Gebis, J. J. and Husbands, P. and Keutzer, K. and Patterson, D. A. and Plishker, W. L. and Shalf, J. and Williams, S. W.}
},

@misc{anon._zynq-7000_2012-1,
	title = {Zynq-7000 All Programmable  {SoC} Software Developers  Guide},
	url = {http://www.xilinx.com/support/documentation/user_guides/ug821-zynq-7000-swdev.pdf},
	urldate = {2013-02-10},
	publisher = {Xilinx},
	author = {{Anon.}},
	month = oct,
	year = {2012}
},

@inproceedings{wakabayashi_c-based_2004,
	address = {Piscataway, {NJ}, {USA}},
	series = {{ASP-DAC} '04},
	title = {C-based behavioral synthesis and verification analysis on industrial design examples},
	isbn = {0-7803-8175-0},
	url = {http://dl.acm.org/citation.cfm?id=1015090.1015177},
	abstract = {This paper presents the effects of {SoC} design with C language-based behavioral synthesis and verification. Initially, the proposed C-based design environment for a large {SOC} consisting of a hardware and embedded software is explained. Next, the increasse of design productivity by shifting from {RTL} to behavioral design will be discussed with statistical analysis of several industrial designs. Then, several merits of C-based design are examined using actual chip design results.},
	urldate = {2013-02-10},
	booktitle = {Proceedings of the 2004 Asia and South Pacific Design Automation Conference},
	publisher = {{IEEE} Press},
	author = {Wakabayashi, Kazutoshi},
	year = {2004},
	pages = {344–348}
},

@article{gac_high_2008,
	title = {High speed {3D} tomography on {CPU}, {GPU}, and {FPGA}},
	volume = {2008},
	issn = {1687-3955},
	url = {http://dx.doi.org/10.1155/2008/930250},
	doi = {10.1155/2008/930250},
	abstract = {Back-projection ({BP)} is a costly computational step in tomography image reconstruction such as positron emission tomography ({PET).} To reduce the computation time, this paper presents a pipelined, prefetch, and parallelized architecture for {PET} {BP} ({3PA-PET).} The key feature of this architecture is its original memory access strategy, masking the high latency of the external memory. Indeed, the pattern of the memory references to the data acquired hinders the processing unit. The memory access bottleneck is overcome by an efficient use of the intrinsic temporal and spatial locality of the {BP} algorithm. A loop reordering allows an efficient use of general purpose processor's caches, for software implementation, as well as the {3D} predictive and adaptive cache ({3D-AP} cache), when considering hardware implementations. Parallel hardware pipelines are also efficient thanks to a hierarchical {3D-AP} cache: each pipeline performs a memory reference in about one clock cycle to reach a computational throughput close to 100\%. The {3PA-PET} architecture is prototyped on a system on programmable chip ({SoPC)} to validate the system and to measure its expected performances. Time performances are compared with a desktop {PC}, a workstation, and a graphic processor unit ({GPU).}},
	urldate = {2012-12-04},
	journal = {{EURASIP} J. Embedded Syst.},
	author = {Gac, Nicolas and Mancini, {StéPhane} and Desvignes, Michel and Houzet, Dominique},
	month = jan,
	year = {2008},
	pages = {5:1–5:12},
	file = {High Speed 3D Tomography on CPU, GPU and FPGA.pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/S4RTJVZH/High Speed 3D Tomography on CPU, GPU and FPGA.pdf:application/pdf}
},

@misc{anon._zynq-7000_2012-2,
	title = {Zynq-7000 All Programmable {SoC} Overview},
	publisher = {Xilinx},
	author = {{Anon.}},
	month = sep,
	year = {2012}
},

@misc{_moores_????-1,
	title = {Moore's Law and Intel Innovation},
	url = {http://www.intel.com/content/www/us/en/history/museum-gordon-moore-law.html},
	abstract = {Learn about Moore’s Law, the business model that drives the semiconductor industry and the exponential growth that continues today.},
	urldate = {2013-01-26},
	journal = {Intel},
	keywords = {moores law},
	file = {Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/TXTQIBFM/museum-gordon-moore-law.html:text/html}
},

@article{crookes_design_2000,
	title = {Design and implementation of a high level programming environment for {FPGA-based} image processing},
	volume = {147},
	issn = {1350-{245X}},
	doi = {10.1049/ip-vis:20000579},
	abstract = {Reconfigurable hardware in the form of field programmable gate arrays ({FPGAs)} has been proposed as a way of obtaining high performance for computationally intensive {DSP} applications such as image processing ({IP)}, even under real time requirements. The inherent reprogrammability of {FPGAs} gives them some of the flexibility of software while keeping the performance advantages of an application specific solution. However, a major disadvantage of {FPGAs} is their low level programming model. To bridge the gap between these two levels, the authors present a high level software environment for {FPGA-based} image processing, which aims to hide hardware details as much as possible from the user. Their approach is to provide a very high level image processing coprocessor ({IPC)} with a core instruction set based on the operations of image algebra. The environment includes a generator which generates optimised architectures for specific user-defined operations},
	number = {4},
	journal = {Vision, Image and Signal Processing, {IEE} Proceedings -},
	author = {Crookes, D. and Benkrid, K. and Bouridane, A. and Alotaibi, K. and Benkrid, A.},
	month = aug,
	year = {2000},
	keywords = {computationally intensive {DSP} applications, coprocessors, core instruction set, digital signal processing chips, field programmable gate arrays, {FPGA-based} image processing, hardware details, high level programming environment, high level software environment, image algebra, image processing, optimised architectures, programming environments, reconfigurable hardware, reprogrammability, user-defined operations, very high level image processing coprocessor},
	pages = {377 --384},
	file = {High Level Programming for Real Time FPGA Image Processing.pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/RC8PVQWF/High Level Programming for Real Time FPGA Image Processing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/3PJH5845/login.html:text/html}
},

@phdthesis{cope_implementation_????,
	title = {Implementation of {2D} Convolution on {FPGA}, {GPU} and {CPU}},
	abstract = {The {2D} convolution algorithm is a memory intensive algorithm with a regular access structure. Implementation on an {FPGA} can exploit data streaming and pipelining. The {GPU} is unable to hold onto previously accessed data, this report exemplifies this limitation. Designs for implementations on {FPGAs}, {GPUs} and the {CPU} are shown and results of their performance analysed. {http://cas.ee.ic.ac.uk/people/btc00/index\_files/Convolution\_filter.pdf} We find the {FPGA} to have a more consistent and higher throughput than both the {GPU} and {CPU.}},
	school = {Department of Electrical \& Electronic Engineering, Imperial College London},
	author = {Cope, Ben},
	keywords = {2d, convolution, {CPU}, {FPGA}, gpgpu},
	file = {Implementation of 2D Convolution on FPGA, GPU and CPU.pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/7M2V2JZI/Implementation of 2D Convolution on FPGA, GPU and CPU.pdf:application/pdf}
},

@inproceedings{plavec_towards_2008,
	title = {Towards compilation of streaming programs into {FPGA} hardware},
	doi = {10.1109/FDL.2008.4641423},
	abstract = {There is an increasing need for automated conversion of high-level design descriptions into hardware. We present a flow that converts a software application written in the Brook streaming language into a hardware description targeting {FPGAs.} We use a combination of our source-to-source compiler and a commercial {C2H} behavioral synthesis compiler. Our approach results in a significant through-put increase compared to software and ordinary {C2H} results (up to {8.9X} and {4.3X}, respectively). The throughput can be further increased by using more hardware resources to exploit data parallelism available in streaming applications.},
	booktitle = {Forum on Specification, Verification and Design Languages, 2008. {FDL} 2008},
	author = {Plavec, F. and Vranesic, Z. and Brown, S.},
	month = sep,
	year = {2008},
	keywords = {Application software, Brook streaming language, Buildings, commercial {C2H} behavioral synthesis compiler, Computer languages, Educational institutions, field programmable gate arrays, {FPGA} hardware, Hardware, Kernel, Parallel processing, program compilers, Programming profession, source-to-source compiler, streaming programs, Throughput},
	pages = {67 --72},
	file = {IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/XEKKRHIR/login.html:text/html}
},

@article{batlle_new_2002,
	title = {A New {FPGA/DSP-Based} Parallel Architecture for Real-Time Image Processing},
	volume = {8},
	issn = {1077-2014},
	url = {http://www.sciencedirect.com/science/article/pii/S1077201401902736},
	doi = {10.1006/rtim.2001.0273},
	abstract = {In this article, we present a new reconfigurable parallel architecture oriented to video-rate computer vision applications. This architecture is structured with a two-dimensional ({2D)} array of {FPGA/DSP-based} reprogrammable processors Pij. These processors are interconnected by means of a systolic {2D} array of {FPGA-based} video-addressing units which allow video-rate links between any two processors in the net to overcome the associated restrictions in classic crossbar systems such as those which occur with butterfly connections. This architecture has been designed to deal with parallel/pipeline procedures, performing operations which handle various simultaneous input images, and cover a wide range of real-time computer vision applications from pre-processing operations to low-level interpretation. This proposed open architecture allows the host to deal with final high-level interpretation tasks. The exchange of information between the linked {processorsPij} of the {2D} net lies in the transfer of complete images, pixel by pixel, at video-rate. Therefore, any kind of processor satisfying such a requirement can be integrated. Furthermore, the whole architecture has been designed host-independent.},
	number = {5},
	urldate = {2013-01-27},
	journal = {Real-Time Imaging},
	author = {Batlle, J. and Martı\&\#x0301;, J. and Ridao, P. and Amat, J.},
	month = oct,
	year = {2002},
	pages = {345--356},
	file = {ScienceDirect Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/GQEPX82J/S1077201401902736.html:text/html}
},

@inproceedings{tsoi_axel:_2010,
	address = {New York, {NY}, {USA}},
	series = {{FPGA} '10},
	title = {Axel: a heterogeneous cluster with {FPGAs} and {GPUs}},
	isbn = {978-1-60558-911-4},
	shorttitle = {Axel},
	url = {http://doi.acm.org/10.1145/1723112.1723134},
	doi = {10.1145/1723112.1723134},
	abstract = {This paper describes a heterogeneous computer cluster called Axel. Axel contains a collection of nodes; each node can include multiple types of accelerators such as {FPGAs} (Field Programmable Gate Arrays) and {GPUs} (Graphics Processing Units). A Map-Reduce framework for the Axel cluster is presented which exploits spatial and temporal locality through different types of processing elements and communication channels. The Axel system enables the first demonstration of {FPGAs}, {GPUs} and {CPUs} running collaboratively for N-body simulation. Performance improvement from 4.4 times to 22.7 times has been achieved using our approach, which shows that the Axel system can combine the benefits of the specialization of {FPGA}, the parallelism of {GPU}, and the scalability of computer clusters.},
	urldate = {2012-12-04},
	publisher = {{ACM}},
	author = {Tsoi, Kuen Hung and Luk, Wayne},
	year = {2010},
	keywords = {{FPGA}, heterogeneous cluster},
	pages = {115–124},
	file = {Axel A Heterogeneous Cluster with FPGAs and GPUs.pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/9H8HQUET/Axel A Heterogeneous Cluster with FPGAs and GPUs.pdf:application/pdf}
},

@book{kirk_programming_2010,
	title = {Programming Massively Parallel Processors: A Hands-on Approach},
	isbn = {9780123814739},
	shorttitle = {Programming Massively Parallel Processors},
	abstract = {Multi-core processors are no longer the future of computing-they are the present day reality. A typical mass-produced {CPU} features multiple processor cores, while a {GPU} (Graphics Processing Unit) may have hundreds or even thousands of cores. With the rise of multi-core architectures has come the need to teach advanced programmers a new and essential skill: how to program massively parallel processors. Programming Massively Parallel Processors: A Hands-on Approach shows both student and professional alike the basic concepts of parallel programming and {GPU} architecture. Various techniques for constructing parallel programs are explored in detail. Case studies demonstrate the development process, which begins with computational thinking and ends with effective and efficient parallel {programs.Teaches} computational thinking and problem-solving techniques that facilitate high-performance parallel {computing.Utilizes} {CUDA} (Compute Unified Device Architecture), {NVIDIA's} software development tool created specifically for massively parallel {environments.Shows} you how to achieve both high-performance and high-reliability using the {CUDA} programming model as well as {OpenCL.}},
	language = {en},
	publisher = {Elsevier},
	author = {Kirk, David B. and Hwu, Wen-mei W.},
	month = feb,
	year = {2010},
	keywords = {Computers / Computer Engineering, Computers / Computer Science, Computers / Hardware / Mainframes \& Minicomputers, Computers / Microprocessors, Computers / Programming / General, Computers / Programming Languages / C, Computers / Programming Languages / General, Computers / Programming / Parallel, Computers / Software Development \& Engineering / General, Computers / Systems Architecture / Distributed Systems \& Computing, Computers / Systems Architecture / General}
},

@inproceedings{villarreal_designing_2010,
	title = {Designing Modular Hardware Accelerators in C with {ROCCC} 2.0},
	doi = {10.1109/FCCM.2010.28},
	abstract = {While {FPGA-based} hardware accelerators have repeatedly been demonstrated as a viable option, their programmability remains a major barrier to their wider acceptance by application code developers. These platforms are typically programmed in a low level hardware description language, a skill not common among application developers and a process that is often tedious and error-prone. Programming {FPGAs} from high level languages would provide easier integration with software systems as well as open up hardware accelerators to a wider spectrum of application developers. In this paper, we present a major revision to the Riverside Optimizing Compiler for Configurable Circuits ({ROCCC)} designed to create hardware accelerators from C programs. Novel additions to {ROCCC} include (1) intuitive modular bottom-up design of circuits from C, and (2) separation of code generation from specific {FPGA} platforms. The additions we make do not introduce any new syntax to the C code and maintain the high level optimizations from the {ROCCC} system that generate efficient code. The modular code we support functions identically as software or hardware. Additionally, we enable user control of hardware optimizations such as systolic array generation and temporal common subexpression elimination. We evaluate the quality of the {ROCCC} 2.0 tool by comparing it to hand-written {VHDL} code. We show comparable clock frequencies and a 18\% higher throughput. The productivity advantages of {ROCCC} 2.0 is evaluated using the metrics of lines of code and programming time showing an average of 15 {\#x00D7;} improvement over hand-written {VHDL.}},
	booktitle = {2010 18th {IEEE} Annual International Symposium on Field-Programmable Custom Computing Machines ({FCCM)}},
	author = {Villarreal, J. and Park, A. and Najjar, W. and Halstead, R.},
	month = may,
	year = {2010},
	keywords = {Application software, Circuits, C language, Clocks, code generation, Compilers, C programs, C-to-{VHDL}, field programmable gate arrays, {FPGA} based hardware accelerators, {FPGAs}, Frequency, handwritten {VHDL} code, hardware description languages, Hardware design languages, hardware optimizations, High level languages, High level synthesis, low level hardware description language, modular hardware accelerators, Optimizing compilers, program compilers, riverside optimizing compiler for configurable circuits, Software systems, systolic array generation, Systolic arrays},
	pages = {127 --134},
	file = {IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/8AKDK4AG/login.html:text/html}
},

@techreport{tom_feist_white_2012,
	title = {White Paper: Vivado Design Suite},
	url = {http://www.xilinx.com/support/documentation/white_papers/wp416-Vivado-Design-Suite.pdf},
	urldate = {2013-10-02},
	institution = {Xilinx},
	author = {{Tom Feist}},
	month = jun,
	year = {2012}
},

@phdthesis{pereira_characterization_2011,
	title = {Characterization of {FPGA-based} High Performance Computers},
	url = {http://scholar.lib.vt.edu/theses/available/etd-08112011-192508/},
	urldate = {2012-12-04},
	author = {Pereira, Karl Savio Pimenta},
	month = sep,
	year = {2011},
	note = {As {CPU} clock frequencies plateau and the doubling of {CPU} cores per processor exacerbate the memory wall, hybrid core computing, utilizing {CPUs} augmented with {FPGAs} and/or {GPUs} holds the promise of addressing high-performance computing demands, particularly with respect to performance, power and productivity.  While traditional approaches to benchmark high-performance computers such as {SPEC}, took an architecture-based approach, they do not completely express the parallelism that exists in {FPGA} and {GPU} accelerators.  This thesis follows an application-centric approach, by comparing the sustained performance of two key computational idioms, with respect to performance, power and productivity.  Specifically, a complex, single precision, floating-point, {1D}, Fast Fourier Transform ({FFT)} and a Molecular Dynamics modeling application, are implemented on state-of-the-art {FPGA} and {GPU} accelerators.  As results show, {FPGA} floating-point {FFT} performance is highly sensitive to a mix of dedicated {FPGA} resources; {DSP48E} slices, block {RAMs}, and {FPGA} {I/O} banks in particular.  Estimated results show that for the floating-point {FFT} benchmark on {FPGAs}, these resources are the performance limiting factor.  Fixed-point {FFTs} are important in a lot of high performance embedded applications. For an integer-point {FFT}, {FPGAs} exploit a flexible data path width to trade-off circuit cost and speed of computation, improving performance and resource utilization.  {GPUs} cannot fully take advantage of this, having a fixed data-width architecture.  For the molecular dynamics application, {FPGAs} benefit from the flexibility in creating a custom, tightly-pipelined datapath, and a highly optimized memory subsystem of the accelerator. This can provide a 250-fold improvement over an optimized {CPU} implementation and 2-fold improvement over an optimized {GPU} implementation, along with massive power savings.  Finally, to extract the maximum performance out of the {FPGA}, each implementation requires a balance between the formulation of the algorithm on the platform, the optimum use of available external memory bandwidth, and the availability of computational resources; at the expense of a greater programming effort.},
	keywords = {{FFT}, floating-point, {FPGA}, {GPU}, {HPC}, integer-point, Master of Science, Master's Thesis, molecular dynamics},
	file = {Characterization of FPGA-based High Performance Computers .pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/WZ7IVVQT/Characterization of FPGA-based High Performance Computers .pdf:application/pdf;Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/73EQWIZM/etd-08112011-192508.html:text/html}
},

@misc{anon._zynq-7000_2013,
	title = {Zynq-7000 All Programmable {SoC} Technical Reference Manual},
	publisher = {Xilinx},
	author = {{Anon.}},
	month = mar,
	year = {2013}
},

@inproceedings{casseau_c-_2005,
	address = {Turquie},
	title = {C- Based Rapid Prototyping For Digital Signal Processing},
	url = {http://hal.archives-ouvertes.fr/hal-00080466},
	abstract = {The increasingly demanding requirements of digital signal processing applications like multimedia, new generations of wireless systems, etc. led to the definition of more and more complex algorithms and systems that are to be efficiently implemented with the time to market constraint. Today, the electronic system design community is mainly concerned with defining efficient System-on-a-Chip ({/SoC/)} design methodologies in order to benefit from the high integration capabilities of current {/ASIC/} and {/FPGA/} technologies on the one hand, and manage the increasing algorithmic complexity of applications on the other hand. Rapid prototyping is considered as a key to speed up the system design. In this context, we have introduced a novel methodology that efficiently addresses both the algorithmic complexity and the high flexibility required by the various application profiles. Our methodology benefits from the emerging High-Level Synthesis ({HLS)} tools in a platform-based approach dedicated to the rapid prototyping of real-time systems. We show the effectiveness of this approach with the design of a {DVB-DSNG} compliant receiver.},
	language = {Anglais},
	urldate = {2013-02-10},
	booktitle = {Proceedings of the European Signal Processing Conference},
	publisher = {{EUSIPCO}},
	author = {Casseau, Emmanuel and Le Gal, Bertrand and Bomel, Pierre and Jego, Christophe and Huet, Sylvain and Martin, Eric},
	year = {2005},
	pages = {1--4},
	file = {HAL Snapshot:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/7H6ED34M/hal-00080466.html:text/html}
},

@article{asanovic_view_2009,
	title = {A view of the parallel computing landscape},
	volume = {52},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/1562764.1562783},
	doi = {10.1145/1562764.1562783},
	abstract = {Writing programs that scale with increasing numbers of cores should be as easy as writing programs for sequential computers.},
	number = {10},
	urldate = {2013-01-26},
	journal = {Commun. {ACM}},
	author = {Asanovic, Krste and Bodik, Rastislav and Demmel, James and Keaveny, Tony and Keutzer, Kurt and Kubiatowicz, John and Morgan, Nelson and Patterson, David and Sen, Koushik and Wawrzynek, John and Wessel, David and Yelick, Katherine},
	month = oct,
	year = {2009},
	pages = {56–67},
	file = {ACM Full Text PDF:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/PR3JUA6T/Asanovic et al. - 2009 - A view of the parallel computing landscape.pdf:application/pdf}
},

@inproceedings{bauer_fpga-gpu_2010,
	title = {{FPGA-GPU} architecture for kernel {SVM} pedestrian detection},
	doi = {10.1109/CVPRW.2010.5543772},
	abstract = {We present a real-time multi-sensor architecture for video-based pedestrian detection used within a road side unit for intersection assistance. The entire system is implemented on available {PC} hardware, combining a frame grabber board with embedded {FPGA} and a graphics card into a powerful processing network. Giving classification performance top priority, we use {HOG} descriptors with a Gaussian kernel support vector machine. In order to achieve real-time performance, we propose a hardware architecture that incorporates {FPGA-based} feature extraction and {GPU-based} classification. The {FPGA-GPU} pipeline is managed by a multi-core {CPU} that further performs sensor data fusion. Evaluation on the {INRIA} benchmark database and an experimental study on a real-world intersection using multi-spectral hypothesis generation confirm state-of-the-art classification and real-time performance.},
	booktitle = {2010 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW)}},
	author = {Bauer, S. and Kohler, S. and Doll, K. and Brunsmann, U.},
	month = jun,
	year = {2010},
	keywords = {computer graphics, coprocessors, feature extraction, field programmable gate arrays, {FPGA} based feature extraction, {FPGA-GPU} architecture, frame grabber board, Gaussian kernel support vector machine, {GPU} based classification, Graphics, Hardware, {HOG} descriptors, {INRIA} benchmark database, Kernel, kernel {SVM} pedestrian detection, multicore {CPU}, multiprocessing systems, multispectral hypothesis generation, Pipelines, real time multisensor architecture, Roads, sensor data fusion, Sensor fusion, statistical analysis, Support vector machine classification, Support vector machines, traffic engineering computing, video based pedestrian detection},
	pages = {61 --68},
	file = {FPGA-GPU Architecture for Kernel SVM Pedestrian Detection.pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/C99BD5BT/FPGA-GPU Architecture for Kernel SVM Pedestrian Detection.pdf:application/pdf;IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/Q34VRMQG/login.html:text/html}
},

@inproceedings{jones_gpu_2010,
	title = {{GPU} Versus {FPGA} for High Productivity Computing},
	doi = {10.1109/FPL.2010.32},
	abstract = {Heterogeneous or co-processor architectures are becoming an important component of high productivity computing systems ({HPCS).} In this work the performance of a {GPU} based {HPCS} is compared with the performance of a commercially available {FPGA} based {HPC.} Contrary to previous approaches that focussed on specific examples, a broader analysis is performed by considering processes at an architectural level. A set of benchmarks is employed that use different process architectures in order to exploit the benefits of each technology. These include the asynchronous pipelines common to "map" tasks, a partially synchronous tree common to "reduce" tasks and a fully synchronous, fully connected mesh. We show that the {GPU} is more productive than the {FPGA} architecture for most of the benchmarks and conclude that {FPGA-based} {HPCS} is being marginalised by {GPUs.}},
	author = {Jones, {D.H.} and Powell, A. and Bouganis, C.-S. and Cheung, {P.Y.K.}},
	month = sep,
	year = {2010},
	keywords = {asynchronous tree, computer graphic equipment, coprocessor architectures, coprocessors, field programmable gate arrays, {FPGA} architecture, {GPU}, heterogeneous architectures, high productivity computing system, {HPC}, parallel architectures},
	pages = {119 --124},
	file = {GPU versus FPGA for high productivity computing .pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/48JTPUNP/GPU versus FPGA for high productivity computing .pdf:application/pdf;IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/MRK5V6RD/login.html:text/html}
},

@book{solem_programming_2012,
	edition = {1},
	title = {Programming Computer Vision with Python: Tools and algorithms for analyzing images},
	isbn = {1449316549},
	shorttitle = {Programming Computer Vision with Python},
	publisher = {{O'Reilly} Media},
	author = {Solem, Jan Erik},
	month = jun,
	year = {2012}
},

@article{wakabayashi_c-based_2000,
	title = {C-based {SoC} design flow and {EDA} tools: an {ASIC} and system vendor perspective},
	volume = {19},
	issn = {0278-0070},
	shorttitle = {C-based {SoC} design flow and {EDA} tools},
	doi = {10.1109/43.898829},
	abstract = {This paper examines the achievements and future of system-on-a-chip ({SoC)} design methodology and design flow from the viewpoints of an in-house electronic design automation team of an application-specific integrated circuit and system vendor. We initially discuss the problems of the design productivity gap caused by the {SoC's} complexity and the timing closure caused by deep-submicrometer technology. To solve these two problems, we propose a C-based {SoC} design environment that features integrated high-level synthesis ({HLS)} and verification tools. A {HLS} system is introduced using various successful industrial design examples, and its advantages and drawbacks are discussed. We then look at the future directions of this system. The high-level verification environment consists of a mixed-level hardware/software co-simulator, formal and semi-formal verifiers, and test-bench generators. The verification tools are tightly integrated with the {HLS} system and take advantage of information from the synthesis system. Then, we discusses the possibility of incorporating physical design features into the C-based {SoC} design environment. Finally, we describe our global vision for an {SoC} architecture and {SoC} design methodology},
	number = {12},
	journal = {{IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Wakabayashi, K. and Okamoto, T.},
	month = dec,
	year = {2000},
	keywords = {application-specific integrated circuit, Application specific integrated circuits, {ASIC} vendor perspective, C-based {SoC} design flow, circuit {CAD}, circuit simulation, C language, deep-submicron technology, Design methodology, design productivity gap, {EDA} tools, Electronic design automation and methodology, electronic design automation team, formal verification, formal verifier, Hardware, High level synthesis, high-level synthesis, high-level verification environment, in-house {EDA} team, integrated circuit design, Integrated circuit technology, integrated {HLS/verification} tools, mixed-level hardware/software co-simulator, physical design features, Productivity, semi-formal verifier, {SoC} architecture, {SoC} design environment, {SoC} design methodology, Software testing, System-on-a-chip, system-on-a-chip design, system vendor perspective, test-bench generators, Timing, timing closure, {VLSI}},
	pages = {1507 --1522},
	file = {IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/NHDWRQV4/login.html:text/html}
},

@article{cope_performance_2010,
	title = {Performance Comparison of Graphics Processors to Reconfigurable Logic: A Case Study},
	volume = {59},
	issn = {0018-9340},
	shorttitle = {Performance Comparison of Graphics Processors to Reconfigurable Logic},
	doi = {10.1109/TC.2009.179},
	abstract = {A systematic approach to the comparison of the graphics processor ({GPU)} and reconfigurable logic is defined in terms of three throughput drivers. The approach is applied to five case study algorithms, characterized by their arithmetic complexity, memory access requirements, and data dependence, and two target devices: the {nVidia} {GeForce} 7900 {GTX} {GPU} and a Xilinx Virtex-4 field programmable gate array ({FPGA).} Two orders of magnitude speedup, over a general-purpose processor, is observed for each device for arithmetic intensive algorithms. An {FPGA} is superior, over a {GPU}, for algorithms requiring large numbers of regular memory accesses, while the {GPU} is superior for algorithms with variable data reuse. In the presence of data dependence, the implementation of a customized data path in an {FPGA} exceeds {GPU} performance by up to eight times. The trends of the analysis to newer and future technologies are analyzed.},
	number = {4},
	journal = {{IEEE} Transactions on Computers},
	author = {Cope, B. and Cheung, {P.Y.K.} and Luk, W. and Howes, L.},
	month = apr,
	year = {2010},
	keywords = {arithmetic complexity, arithmetic intensive algorithms, computational complexity, computer graphics, coprocessors, data dependence, field programmable gate arrays, {FPGA}, general-purpose processor, graphics processor, graphics processors, memory access requirements, {nVidia} {GeForce} 7900 {GTX} {GPU}, reconfigurable logic, target devices:, Xilinx Virtex-4 field programmable gate array},
	pages = {433 --448},
	file = {IEEE Xplore Abstract Record:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/V6GKG3SG/login.html:text/html;Performance Comparison of Graphics Processors to Reconfigurable Logic A Case Study .pdf:/home/frank/.zotero/zotero/cjni3anq.default/zotero/storage/CWPCT7SA/Performance Comparison of Graphics Processors to Reconfigurable Logic A Case Study .pdf:application/pdf}
}